{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General\n",
    "from os import listdir, makedirs\n",
    "from collections import defaultdict\n",
    "from os.path import join, isdir, splitext\n",
    "import string\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from plotcm import plot_confusion_matrix\n",
    "\n",
    "# Math\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Image processing\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "from torch.nn.modules.activation import ReLU\n",
    "from torch.nn.modules.pooling import MaxPool2d\n",
    "from torchvision import datasets\n",
    "import torchvision\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters / configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blur parameters\n",
    "kernel = (3, 3)\n",
    "level = 2\n",
    "\n",
    "# Dataset path\n",
    "raw_path = r\"dataset\\raw12\"\n",
    "seg_path = r\"dataset\\segmented\"\n",
    "pad_path = r\"dataset\\padded\"\n",
    "test_path = r'dataset\\test'\n",
    "test_data_path = r'dataset\\test_resize_test'\n",
    "\n",
    "# Data view of samples - choose the dimensions of plot. Total CAPTHAs = row*col\n",
    "row = 2\n",
    "col = 4\n",
    "\n",
    "# CNN\n",
    "DATA_DIR = \"archive\\samples\"\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "IMAGE_WIDTH = 300\n",
    "IMAGE_HEIGHT = 75\n",
    "NUM_WORKERS = 8\n",
    "EPOCHS = 200\n",
    "DEVICE = \"cuda\"\n",
    "\n",
    "GBS = 1000 # Global batch size\n",
    "CH1 = 25 # First channel selection (out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading images and counting characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allowed_chars = string.ascii_lowercase + string.digits # abcdefghijklmnopqrstuvwxyz0123456789\n",
    "\n",
    "if not isdir(seg_path):\n",
    "    makedirs(seg_path)\n",
    "\n",
    "    for i in allowed_chars:\n",
    "        makedirs(seg_path + \"/\" + i)\n",
    "\n",
    "files = listdir(raw_path) # Files in directory with raw CAPTCHAs\n",
    "\n",
    "counts = defaultdict(int) # Default dict to count number of each symbol\n",
    "\n",
    "# Show unique characters/labels\n",
    "temp = []\n",
    "for file in files:\n",
    "    temp.append(splitext(file)[0])\n",
    "characters = set(char for label in temp for char in label)\n",
    "print(f'Unique characters/labels: \\n{characters}')\n",
    "print(f'Number of unique characters/labels: {len(characters)}')\n",
    "\n",
    "UC = len(characters) # Keeping number of unique characters for CNN output features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering and segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of files:', len(files))\n",
    "for file in files:\n",
    "    image = cv2.imread(raw_path + '\\\\' + file, 0)\n",
    "    letters = splitext(file)[0]\n",
    "\n",
    "    # blur\n",
    "    k = np.ones((5,5),np.float32)/25\n",
    "    dst = cv2.filter2D(image,-1,k)\n",
    "\n",
    "    # threshold\n",
    "    ret, image = cv2.threshold(dst, 110, 255, cv2.THRESH_BINARY_INV)\n",
    "    image = cv2.erode(image, kernel, iterations = level)\n",
    "\n",
    "    connectivity = 4\n",
    "    output = cv2.connectedComponentsWithStats(image, connectivity, cv2.CV_32S)\n",
    "\n",
    "    num_labels = output[0]\n",
    "    labels = output[1]\n",
    "    stats = output[2]\n",
    "    centroids = output[3]\n",
    "\n",
    "    objects = []\n",
    "\n",
    "    for i in range(1, num_labels):\n",
    "        a = stats[i, cv2.CC_STAT_AREA]\n",
    "\n",
    "        if a > 50:\n",
    "            x = stats[i, cv2.CC_STAT_LEFT]\n",
    "            y = stats[i, cv2.CC_STAT_TOP]\n",
    "            w = stats[i, cv2.CC_STAT_WIDTH]\n",
    "            h = stats[i, cv2.CC_STAT_HEIGHT]\n",
    "\n",
    "            objects.append((x, y, w, h))\n",
    "\n",
    "    objects.sort(key=lambda t: t[0])\n",
    "\n",
    "    num_detected = min(len(objects), 4)\n",
    "\n",
    "    for i in range(num_detected):\n",
    "        o = objects[i]\n",
    "        x = o[0]\n",
    "        y = o[1]\n",
    "        w = o[2]\n",
    "        h = o[3]\n",
    "\n",
    "        img = image[y:y+h, x:x+w]\n",
    "        rgb = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "        letter = letters[i]\n",
    "        \n",
    "        filename = str(counts[letter]).zfill(5) + \".png\" #\"\\\\\" + str(counts[letter]).zfill(5) + \".png\" # <symbol><number of symbols with zero fill>.png\n",
    "        \n",
    "        path = seg_path + \"\\\\\" + letter + filename\n",
    "        cv2.imwrite(path, img)\n",
    "        counts[letter] += 1\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CAPTCHA samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = plt.figure(figsize=(14,4))\n",
    "\n",
    "for i in range(1, col*row + 1):\n",
    "    img = cv2.imread(raw_path + '\\\\' + files[i],0)\n",
    "    plot = fig.add_subplot(row, col, i)\n",
    "    plot.title.set_text(splitext(files[i])[0])\n",
    "    plt.imshow(img, cmap='binary')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CAPTCHA segmentation samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = row*col # Choosen at the top (parameters / configuration)\n",
    "col = 4\n",
    "orig_row = row\n",
    "row = samples\n",
    "\n",
    "# Get path to letters of <samples> CAPTCHAs\n",
    "letter_paths = []\n",
    "letter_sample = [[char for char in splitext(sample)[0]] for sample in files[1:samples + 1]]\n",
    "letter_count = defaultdict(int)\n",
    "for w in letter_sample:\n",
    "    for i, l in enumerate(w):\n",
    "        letter_paths.append(seg_path + '\\\\' + l + str(letter_count[l]).zfill(5) + '.png')\n",
    "        letter_count[l] += 1\n",
    "\n",
    "# Plot segmented CAPTCHAs\n",
    "fig = plt.figure(figsize = (10,30))\n",
    "for i in range(1, col*row + 1):\n",
    "    img = cv2.imread(letter_paths[i-1])\n",
    "    plot = fig.add_subplot(row, col, i)\n",
    "    plot.title.set_text(letter_paths[i-1][18:-9])\n",
    "    plt.axis('equal')\n",
    "    plt.imshow(img, cmap='binary')\n",
    "plt.show()\n",
    "row = orig_row # Resetting it so it doesn't multiply rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in listdir(seg_path):\n",
    "\n",
    "       img = cv2.imread(seg_path + '\\\\' + file)\n",
    "\n",
    "       old_image_height, old_image_width, channels = img.shape\n",
    "\n",
    "       # create new image of desired size and color (blue) for padding\n",
    "       new_image_width = 71\n",
    "       new_image_height = 71\n",
    "       color = (0,0,0) #Black\n",
    "       result = np.full((new_image_height,new_image_width, channels), color, dtype=np.uint8)\n",
    "\n",
    "       # compute center offset\n",
    "       x_center = (new_image_width - old_image_width) // 2\n",
    "       y_center = (new_image_height - old_image_height) // 2\n",
    "\n",
    "       # copy img image into center of result image\n",
    "       result[y_center:y_center+old_image_height, \n",
    "              x_center:x_center+old_image_width] = img\n",
    "\n",
    "       path = pad_path + '\\\\' + file\n",
    "       cv2.imwrite(path, result)\n",
    "\n",
    "plt.imshow(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding and dataframe (train data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = test_path\n",
    "df = pd.DataFrame(columns = ['data','targets'])\n",
    "for filename in os.listdir(dir):\n",
    "    if '.png' in filename:\n",
    "        f = os.path.join(dir, filename)\n",
    "        # checking if it is a file\n",
    "        if os.path.isfile(f):\n",
    "            \n",
    "            data = Image.open(f).convert('L') # Converts to one channel grayscale\n",
    "            trans = ToTensor()\n",
    "            data = trans(data)#np.squeeze(trans(data)) # Formats and converts image to tensor\n",
    "            label = filename[0]\n",
    "            to_append = [data, label]\n",
    "            a_series = pd.Series(to_append, index = df.columns)\n",
    "            df = df.append(a_series, ignore_index=True)\n",
    "\n",
    "\n",
    "le = LabelEncoder()\n",
    "df.targets = le.fit_transform(df.targets) # https://vitalflux.com/labelencoder-example-single-multiple-columns/\n",
    "map = dict(zip(le.classes_, range(len(le.classes_))))\n",
    "inv_map = {v: k for k, v in map.items()}\n",
    "\n",
    "print('Number of targets/labels/classes:',len(le.classes_))\n",
    "print('Number of keys in map:',len(map))\n",
    "print('Map:\\n', map)\n",
    "print('Inverse map:', inv_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding and dataframe (test data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = test_data_path\n",
    "df_test = pd.DataFrame(columns = ['data','targets'])\n",
    "for filename in os.listdir(dir):\n",
    "    if '.png' in filename:\n",
    "        f = os.path.join(dir, filename)\n",
    "        # checking if it is a file\n",
    "        if os.path.isfile(f):\n",
    "            \n",
    "            data = Image.open(f).convert('L') # Converts to one channel grayscale\n",
    "            trans = ToTensor()\n",
    "            data = trans(data)#np.squeeze(trans(data)) # Formats and converts image to tensor\n",
    "            label = filename[0]\n",
    "            to_append = [data, label]\n",
    "            a_series = pd.Series(to_append, index = df.columns)\n",
    "            df_test = df_test.append(a_series, ignore_index=True)\n",
    "\n",
    "\n",
    "le2 = LabelEncoder()\n",
    "df_test.targets = le2.fit_transform(df_test.targets) # https://vitalflux.com/labelencoder-example-single-multiple-columns/\n",
    "map2 = dict(zip(le.classes_, range(len(le.classes_))))\n",
    "inv_map2 = {v: k for k, v in map.items()}\n",
    "\n",
    "print('Number of targets/labels/classes:',len(le2.classes_))\n",
    "print('Number of keys in map:',len(map2))\n",
    "print('Map:\\n', map2)\n",
    "print('Inverse map:', inv_map2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset & dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA LOADER TESTING\n",
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.dataframe = dataframe\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.dataframe.iloc[index]\n",
    "        return (\n",
    "            row['data'],\n",
    "            torch.tensor(row['targets'])\n",
    "        )\n",
    "\n",
    "dataset = MyDataset(df)\n",
    "testset = MyDataset(df_test)\n",
    "# Data example\n",
    "#x,y = next(iter(dataset))\n",
    "print(dataset[:][1])\n",
    "\n",
    "test_loader = DataLoader(dataset, batch_size=GBS, shuffle = True) # Shuffle makes sure the loss function doesn't spike\n",
    "train_loader = DataLoader(testset, batch_size=GBS, shuffle = True)\n",
    "print(f'Train datapoints: {len(train_loader.dataset)}')\n",
    "print(f'Test datapoints: {len(test_loader.dataset)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CH1 = 50\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "# Create Neural Network (Convolutional)\n",
    "class CaptchaSolver(torch.nn.Module):\n",
    "    CH1 = 25 #####################################\n",
    "    def __init__(self):\n",
    "        super(CaptchaSolver,self).__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(in_channels=1, out_channels=CH1, kernel_size=2)\n",
    "        self.relu1 = torch.nn.ReLU()\n",
    "        self.maxpool1 = torch.nn.MaxPool2d(kernel_size=2)\n",
    "        self.conv2 = torch.nn.Conv2d(in_channels=CH1, out_channels=20, kernel_size=3)\n",
    "        self.bnorm = torch.nn.BatchNorm2d(20)\n",
    "        self.drop = torch.nn.Dropout(0.25)\n",
    "        self.relu2 = torch.nn.ReLU()\n",
    "        self.maxpool2 = torch.nn.MaxPool2d(kernel_size=2)\n",
    "        self.flatten = torch.nn.Flatten()\n",
    "        self.linear = torch.nn.Linear(in_features=500, out_features=len(le.classes_))\n",
    "        self.bnorm2 = torch.nn.BatchNorm1d(len(le.classes_))\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bnorm(x)\n",
    "        #x = self.drop(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.linear(x)\n",
    "        #x = self.bnorm2(x)\n",
    "        return x\n",
    "\n",
    "# Creating model\n",
    "model = CaptchaSolver()\n",
    "model.to(device)\n",
    "summary(model, (1,28,28), device='cuda')\n",
    "\n",
    "# Defining loss with nn.CrossEntropyLoss\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Defining optimizer optim.Adam\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 101\n",
    "all_loss = []\n",
    "acc = []\n",
    "test_loss_plt = []\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = 0.\n",
    "    for i,(x,y) in enumerate(train_loader):\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        y = y.to(torch.uint8)\n",
    "        out = model(x)\n",
    "        l = loss(out, y)\n",
    "        optimizer.zero_grad()\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += l\n",
    "        \n",
    "        if i%100 == 0:\n",
    "            print(f'Train loss = {l:.5f}')\n",
    "            #plt.plot(np.array(all_loss))\n",
    "            #plt.show()\n",
    "    all_loss += [train_loss.cpu().detach().numpy()/len(train_loader.dataset)]\n",
    "\n",
    "    test_loss = 0.\n",
    "    for x, y in test_loader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        y = y.to(torch.uint8)\n",
    "        out = model(x)\n",
    "        l = loss(out,y)\n",
    "        pred = out.max(1).indices\n",
    "        acc = (sum(pred == y)/GBS)*100\n",
    "        test_loss += l\n",
    "        \n",
    "\n",
    "    test_loss_plt += [test_loss.cpu().detach().numpy()/len(test_loader.dataset)]\n",
    "    print(f'Epoch: {epoch}          Batch size = {GBS}')\n",
    "    print(f'Batch accuracy: {acc:.2f}%')\n",
    "    plt.plot(np.array(all_loss),label='Train loss')\n",
    "    plt.plot(np.array(test_loss_plt), label='Validation loss')\n",
    "    plt.legend(loc=\"upper left\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Rendering individual images and predictions\n",
    "for _ in range(50):\n",
    "    x = x.to('cpu') # Preventing CUDA compatibility errors\n",
    "    model.to('cpu')\n",
    "    plt.figure()\n",
    "    plt.title(torch.argmax(model(x)[_])) # Adding title of prediction\n",
    "    plt.imshow(x[_][0]) # Rendering image of label\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formatting predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case model didn't finish training\n",
    "def get_num_correct(preds, labels):\n",
    "    return preds.argmax(dim=1).eq(labels).sum().item()\n",
    "\n",
    "def get_all_preds(net,loader):\n",
    "    all_preds = torch.tensor([])\n",
    "    for batch in loader:\n",
    "        images, labels = batch\n",
    "        preds = net(images)\n",
    "        all_preds = torch.cat(\n",
    "            (all_preds,preds)\n",
    "            ,dim=0\n",
    "        )\n",
    "    return all_preds\n",
    "\n",
    "with torch.no_grad():\n",
    "    prediction_loader = DataLoader(testset, batch_size=1000)\n",
    "    train_preds = get_all_preds(model.to('cpu'), prediction_loader)\n",
    "    \n",
    "preds_correct = get_num_correct(train_preds, testset[:][1])\n",
    "print(f'Total correct: {preds_correct} out of {len(testset[:][1])}')\n",
    "print('Accuracy: {:.2f}%'.format(preds_correct / len(testset[:][1])*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked = torch.stack(\n",
    "    (\n",
    "        testset[:][1]\n",
    "        , train_preds.argmax(dim=1)\n",
    "    )\n",
    "    , dim=1\n",
    ")\n",
    "stacked[0].tolist()\n",
    "\n",
    "cmt = torch.zeros(36,36,dtype=torch.int32)\n",
    "\n",
    "for s in stacked:\n",
    "    tl, pl = s.tolist()\n",
    "    cmt[tl,pl] = cmt[tl,pl] + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(testset[:][1], train_preds.argmax(dim=1))\n",
    "names = []\n",
    "for l in map:\n",
    "    names.append(str(l))\n",
    "names = tuple(names)\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "plot_confusion_matrix(cm, names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confidence interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confidence interval function\n",
    "def CT(p, n, a):\n",
    "    iv = a * sqrt( ((p*(1-p))/n) )\n",
    "    #return (p-iv)*100, (p+iv)*100\n",
    "    return iv\n",
    "# Values\n",
    "CIs = []\n",
    "#Model1 with bartch norm\n",
    "crit_val = 1.96 # 95% confidence\n",
    "proportion1 = 0.900191152375751 # This is from confusion matrix accuracy calculation\n",
    "sample_observations = 21972\n",
    "CIs.append(CT(proportion1, sample_observations, crit_val))\n",
    "\n",
    "#Model 2 without batch norm\n",
    "crit_val = 1.96 # 95% confidence\n",
    "proportion2 = 0.8667394866193336 # This is from confusion matrix accuracy calculation\n",
    "sample_observations = 21972\n",
    "CIs.append(CT(proportion2, sample_observations, crit_val))\n",
    "\n",
    "#Model 3 without batch norm but with dropout\n",
    "crit_val = 1.96 # 95% confidence\n",
    "proportion3 = 0.8840342253777536 # This is from confusion matrix accuracy calculation\n",
    "sample_observations = len(testset[:][1])\n",
    "CIs.append(CT(proportion3, sample_observations, crit_val))\n",
    "\n",
    "print(CIs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "crit_val = 1.96 # 95% confidence\n",
    "proportion = preds_correct / len(testset[:][1]) # This is from confusion matrix accuracy calculation\n",
    "sample_observations = len(testset[:][1])\n",
    "\n",
    "\n",
    "labels = [f'M1: {CIs[1]*100:.2f}%', f'M2: {CIs[2]*100:.2f}%',f'M3: {CIs[0]*100:.2f}%']\n",
    "means = [proportion2,proportion3,proportion1]\n",
    "positions = [0,1,2]\n",
    "plt.ylim(0.85,0.92)\n",
    "plt.bar(positions, means,color='tab:blue', yerr=CIs, width = 0.8, align='center', ecolor='black', capsize=50)\n",
    "plt.ylabel('Proportion mellem 0 og 1')\n",
    "plt.title('KONFIDENSINTERVAL')\n",
    "plt.xticks(positions, labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CAPTCHA human benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = 900\n",
    "col = 6\n",
    "row = 4\n",
    "fig = plt.figure(figsize=(14,8*(row/2)))\n",
    "for i in range(1, col*row + 1):\n",
    "    TL = inv_map[int(testset[i*steps][1])]\n",
    "    AIP = inv_map[int(train_preds.argmax(dim=1)[i*steps])]\n",
    "    plot = fig.add_subplot(row, col, i)\n",
    "    plot.title.set_text(f'TL: {TL}  AIP: {AIP}')\n",
    "    plt.imshow(np.squeeze(testset[i*steps][0]))  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset, batch_size=GBS)\n",
    "\n",
    "x,y = next(iter(train_loader))\n",
    "\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "print('TEST:',type(y))\n",
    "plt.imshow(x[0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST data load test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_mnist = datasets.MNIST(root='data', train=True, transform=ToTensor(), download=True)\n",
    "test_data_mnist = datasets.MNIST(root='data', train=False, transform=ToTensor(), download=True)\n",
    "\n",
    "#Example of data\n",
    "x_mnist = train_data_mnist.data[0]\n",
    "y_mnist = train_data_mnist.targets[0]\n",
    "\n",
    "# Make train and test dataloaders\n",
    "train_loader_mnist = DataLoader(train_data_mnist, batch_size=GBS)\n",
    "test_loader_mnist= DataLoader(test_data_mnist, batch_size=GBS)\n",
    "\n",
    "# Extract batch using next(iter(...))\n",
    "xm, ym = next(iter(train_loader_mnist))\n",
    "\n",
    "print(xm.shape)\n",
    "print(ym.shape)\n",
    "print(ym)\n",
    "plt.imshow(xm[0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "72d35e0c788eed675a538630783dd674bb786417aa5acd52bed34fb439755cd9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
